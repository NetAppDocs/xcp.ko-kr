---
sidebar: sidebar 
permalink: xcp-configure-hdfs-connector-nfs.html 
keywords: xcp, nfs, hdfs, connector, configure 
summary: HDFS 커넥터를 통해 XCP는 다양한 공급업체에서 사용할 수 있는 모든 HDFS 파일 시스템에 액세스할 수 있습니다. 
---
= HDFS 커넥터를 구성합니다
:allow-uri-read: 


[role="lead"]
xCP NFS의 경우 HDFS(Hadoop Distributed File System) 커넥터(HDFS://)를 통해 xCP는 다양한 공급업체에서 제공하는 모든 HDFS 파일 시스템에 액세스할 수 있습니다.

.지원되는 기능
HDFS 커넥터에는 HDFS에서 NFS로 복제 명령 작업이 지원됩니다.

.경로 구문
HDFS 커넥터의 경로 구문은 "HDFS://[user@host:port]/full-path"입니다.


NOTE: 사용자, 호스트, 포트를 지정하지 않으면 xCP는 호스트 세트가 'default'이고 포트가 '0'으로 설정된 hdfsConnect를 호출합니다.

.HDFS 커넥터를 설정합니다
HDFS "copy" 명령을 실행하려면 Linux 시스템에서 HDFS 클라이언트를 설정하고 Hadoop 공급업체에 따라 인터넷에서 사용 가능한 설정 구성을 따라야 합니다. 예를 들어, https://docs.datafabric.hpe.com/60/AdvancedInstallation/SettingUptheClient-redhat.html` 을 사용하여 MapR 클러스터에 대한 클라이언트를 설정할 수 있습니다.

HFDS 클라이언트 설정을 완료한 후에는 클라이언트에서 구성을 완료해야 합니다. xCP 명령과 함께 HDFS 경로를 사용하려면 다음 환경 변수가 있어야 합니다.

* NHDFS_LIBHDFS_path입니다
* NHDFS_LIBJVM_PATH


다음 예에서는 CentOS에서 MapR 및 Java-1.8.0-openjdk-devel에 대한 설정이 작동합니다.

[listing]
----
export JAVA_HOME=$(dirname $(dirname $(readlink $(readlink $
(which javac)))))
export NHDFS_LIBJVM_PATH=`find $JAVA_HOME -name "libjvm.so"` export
NHDFS_LIBHDFS_PATH=/opt/mapr/lib/libMapRClient.so
----
[listing]
----
[demo@mapr0 ~]$ hadoop fs -ls Found 3 items
drwxr-xr-x - demo mapr 0 2021-01-14 00:02 d1
drwxr-xr-x - demo mapr 0 2021-01-14 00:02 d2
drwxr-xr-x - demo mapr 0 2021-01-14 00:02 d3
----